import os
import json
import nltk
from nltk.corpus import stopwords
from collections import Counter

# ğŸ”¹ Ensure stopwords are downloaded once
nltk.download('stopwords', quiet=True)

# ğŸ“‚ Load product description
try:
    with open("../content_generator/product.json", "r") as f:
        product = json.load(f)
        description = product.get("description", "")
except FileNotFoundError:
    print("âŒ product.json not found.")
    exit()

# ğŸ§¼ Clean and process text
words = description.lower().split()
words = [word.strip(".,!?()[]\"'") for word in words]  # Remove punctuation
words = [word for word in words if word and word not in stopwords.words("english")]

# ğŸ“Š Generate most common keywords
word_freq = Counter(words)
top_tags = [tag for tag, count in word_freq.most_common(8)]

# âœ… Output and store
print("âœ… Auto-generated tags (offline):")
print(top_tags)

# ğŸ“ Save tags inside product.json
product["auto_tags"] = top_tags
with open("../content_generator/product.json", "w") as f:
    json.dump(product, f, indent=4)

# ğŸ’¾ Also save to bonus/auto_tags.json
os.makedirs("../bonus", exist_ok=True)
with open("../bonus/auto_tags.json", "w") as f:
    json.dump({"tags": top_tags}, f, indent=4)
